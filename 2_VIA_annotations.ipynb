{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_VIA_annotations.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVVeYJABWYWg"
      },
      "source": [
        "# Annotate your imagery to create CNN training and testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0St1FqMD_agV"
      },
      "source": [
        "**If you are viewing this script in GitHub note that I can't get the images to display on GitHub's viewer. You can view this script in Colab, Jupyter Notebook, or a similar markdown viewer to load the files in-line. Alternatively, you can open each image file manually by right-clicking the broken image icon, or accessing the URL displayed next to it.**\n",
        "\n",
        "Strictly speaking none of this step takes place in python, so Colab or Jupyter environments are suggested only for cosmetics and consistency with other steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utvRPG2f_agW"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gl7176/GreySealCNN/blob/master/2_VIA_annotations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8qdU9XBWYXB"
      },
      "source": [
        "On your local machine you should have a tiled dataset, produced from your source orthomosaic in Step 1. The work for this step takes place outside of python, using an HTML tool with lots of manual input on your local computer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX8WVijmWYXC"
      },
      "source": [
        "We will be using VIA, a pre-made tool for annotating imagery: download this tool at http://www.robots.ox.ac.uk/~vgg/software/via/\n",
        "\n",
        "You will probably end up grabbing [this file](https://www.robots.ox.ac.uk/~vgg/software/via/downloads/via-2.0.10.zip) (`via-2.0.10.zip` at the time this was written) but note that this could change if VGG updates the software or the website's file directories.\n",
        "\n",
        "We recommend exploring the tool through the demonstrations section on the linked page above, but we have also made a basic tutorial in this document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96COX197WYXD"
      },
      "source": [
        "## A tutorial tailored to this workflow:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNxEjaE_WYXD"
      },
      "source": [
        "Once you have downloaded and extracted the folder containing VIA's files, open `via.html` and you should see a new blank project with an automatically assigned default name (change that if you like).\n",
        "\\\n",
        "\\\n",
        <iframe src="https://drive.google.com/file/d/1mEEAwf_78xfJr5YIabj9X-9JQM4zTt-_/preview" width="640" height="480" allow="autoplay"></iframe>
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOc-lfSVWYXE"
      },
      "source": [
        "Click the `\"Add Files\"` button under the `\"Project\"` tab on the left panel, and navigate to the directory containing your tiled data files (generated in `Step 1` of this workflow). Select all files and click `\"Open\"`) to load all your tiled data files into VIA. \n",
        "\n",
        "Note that the tiling process can generate mostly empty tiles at a mosaic's margins (we've updated the code to exclude most of them, but some might still occur). Be sure to include these files in your project if they were on the google drive (we need the complete tile set), but you can quickly skip over them during the following annotation process.\n",
        "\\\n",
        "\\\n",
        "![https://duke.box.com/shared/static/0tvxt82wqew29u0620w2es8bqu39cc8y.png](https://duke.box.com/shared/static/0tvxt82wqew29u0620w2es8bqu39cc8y.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aGbLnlPWYXE"
      },
      "source": [
        "Before making any annotations, set up any classes you will be distinguishing using the `\"attributes\"` tab on the left panel (you can skip this if you are only training a CNN to detect 1 class of objects). Here we have created a class type, `\"age_class\"`, with two categories: `\"adult\"` and `\"pup\"`, which will be selected by radio buttons, with `\"adult\"` set as the default category. You can pick whatever \"type\" of category assignment you want and change or omit the default setting, as fits your style and preference, feel free to experiment!\n",
        "\\\n",
        "\\\n",
        "![https://duke.box.com/shared/static/q74r7pf8hitvnhngwk6y2ilv11s8p917.png](https://duke.box.com/shared/static/q74r7pf8hitvnhngwk6y2ilv11s8p917.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFBSd6J9WYXF"
      },
      "source": [
        "Here we have navigated to an example image with many seals, both adults and pups, and we have annotated some of them with boxes. Note that although it is possible to annotate using other polygons, for this workflow we can only annotate using rectangles (unless you would like to customize the code to handle other polygons).\n",
        "\n",
        "In  example annotation 8 below we you can see the class selection box. See that it is pre-populated with the \"adult seal\" default category, even though we have highlighted a pup. Be careful if you use a default category because it might be easier to accidentally mislabel annotations.\n",
        "\n",
        "Depending on your project you might choose to include an \"unknown\" or \"uncertain\" category for your own benefit, but this workflow is not currently designed to handle that during CNN training and testing (the code is written to disregard an \"unknown\" category).\n",
        "\n",
        "Do not annotate \"partial\" seals that are clipped at the edge of the tile; these should not be used for training, and our tiles should have been generated with enough overlap to ensure that \"partial\" seals are \"complete\" in an adjacent tile.\n",
        "\\\n",
        "\\\n",
        "![https://duke.box.com/shared/static/q62eh79ft97sx3vugmoun6ljlw0kb64t.png](https://duke.box.com/shared/static/q62eh79ft97sx3vugmoun6ljlw0kb64t.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc17skuHWYXF"
      },
      "source": [
        "If you need to take a break from annotating or back up your work (recommended) you can save your project and load it later using the `\"Project\"` menu.\n",
        "\\\n",
        "\\\n",
        "![https://duke.box.com/shared/static/4wvyuhb8hgpmeii77wyhvh3rhbt2baw2.png](https://duke.box.com/shared/static/4wvyuhb8hgpmeii77wyhvh3rhbt2baw2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjJ2uP_CWYXF"
      },
      "source": [
        "Finally, when you have finished annotating all images export your annotations as a `csv` file using the `\"Annotation\"` menu.\n",
        "\\\n",
        "\\\n",
        "![https://duke.box.com/shared/static/gxpiem7j5j6marxhuuy2ymdxjf7jnbx5.png](https://duke.box.com/shared/static/gxpiem7j5j6marxhuuy2ymdxjf7jnbx5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EH2AzZOWYXG"
      },
      "source": [
        "VIA has a lot of keyboard shortcuts and functionality not covered in this tutorial (e.g. correcting mistakes, modifying and deleting annotations, navigating between images, etc.), so definitely explore the software if you're planning to spend a lot of time with it! This tutorial only covers the essential basics for the purpose of this workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRf4qsdtWYXG"
      },
      "source": [
        "When finished exporting your annotations, upload your `csv` file to the google drive folder where you are hosting the rest of your data (the orthomosaic, tiles, and `spatial_data.json` file that we have generated so far). This annotation file will be pulled from the google drive folder and used in subsequent steps.\r\n",
        "\r\n",
        "For the rest of this workflow, we will be using [this VIA annotations file](https://duke.box.com/s/wn0ezrmoup5j5mumnuzr8fsxz2smga2o), prepared by Duke student Candice Sheehan using our example dataset."
      ]
    }
  ]
}
